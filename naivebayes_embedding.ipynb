{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled91.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHSy2CCEGEco"
      },
      "source": [
        "#In this notebook I play with a notebook i found for using Naive Bayes parameters for weights in Embedding\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, dot\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import load_files\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oamgt_m9GI-X",
        "outputId": "4b573496-a7b8-46cf-e244-b9f6a9cf1e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imdb_data = tf.keras.datasets.imdb.load_data(path='imdb.npz', )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT7WHGr_VmAt"
      },
      "source": [
        "word_to_index = tf.keras.datasets.imdb.get_word_index(path='imdb.npz')\n",
        "index_to_word = { y:x for x,y in word_to_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CScrJOmoYXQf",
        "outputId": "4aab9c96-9493-478f-edcf-5889c73a9f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( len(word_to_index) )\n",
        "print( len(index_to_word) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88584\n",
            "88584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKC9RJfnWAyl",
        "outputId": "0821cee6-429d-46be-9709-d0e5110bde1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( list(word_to_index.items() )[0:10] )\n",
        "print( list(index_to_word.items() )[0:10] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('fawn', 34701), ('tsukino', 52006), ('nunnery', 52007), ('sonja', 16816), ('vani', 63951), ('woods', 1408), ('spiders', 16115), ('hanging', 2345), ('woody', 2289), ('trawling', 52008)]\n",
            "[(34701, 'fawn'), (52006, 'tsukino'), (52007, 'nunnery'), (16816, 'sonja'), (63951, 'vani'), (1408, 'woods'), (16115, 'spiders'), (2345, 'hanging'), (2289, 'woody'), (52008, 'trawling')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVLqOBqJGZZa"
      },
      "source": [
        "(trainx,y_train),(testx,y_test) = imdb_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARHSuEeOLYhI",
        "outputId": "ed127240-614b-4075-c882-600e0673c81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "\" \".join([str(x) for x in trainx[0] ] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1 14 22 16 43 530 973 1622 1385 65 458 4468 66 3941 4 173 36 256 5 25 100 43 838 112 50 670 22665 9 35 480 284 5 150 4 172 112 167 21631 336 385 39 4 172 4536 1111 17 546 38 13 447 4 192 50 16 6 147 2025 19 14 22 4 1920 4613 469 4 22 71 87 12 16 43 530 38 76 15 13 1247 4 22 17 515 17 12 16 626 18 19193 5 62 386 12 8 316 8 106 5 4 2223 5244 16 480 66 3785 33 4 130 12 16 38 619 5 25 124 51 36 135 48 25 1415 33 6 22 12 215 28 77 52 5 14 407 16 82 10311 8 4 107 117 5952 15 256 4 31050 7 3766 5 723 36 71 43 530 476 26 400 317 46 7 4 12118 1029 13 104 88 4 381 15 297 98 32 2071 56 26 141 6 194 7486 18 4 226 22 21 134 476 26 480 5 144 30 5535 18 51 36 28 224 92 25 104 4 226 65 16 38 1334 88 12 16 283 5 16 4472 113 103 32 15 16 5345 19 178 32'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdbAg-OSHx7F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26vRZ1BVO42N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuQBhMJmQkz0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIZ8e_vqQfhN"
      },
      "source": [
        " veczr =  CountVectorizer(ngram_range=(1,3), binary=True,   token_pattern=r'\\w+', max_features=len(index_to_word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvAzMMFpRPkX"
      },
      "source": [
        "#join indices as a sentence \n",
        "train_data = [ \" \".join([str(y) for y in x]) for x in trainx]\n",
        "test_data = [ \" \".join([str(y) for y in x]) for x in testx]\n",
        "\n",
        "dtm_train  = veczr.fit_transform(train_data)\n",
        "dtm_test   = veczr.transform(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip7IjHMTX2A8",
        "outputId": "fd4589e1-54e9-4295-c9dd-64c06bc258bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_data[0])\n",
        "print(dtm_train[0].indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 14 22 16 43 530 973 1622 1385 65 458 4468 66 3941 4 173 36 256 5 25 100 43 838 112 50 670 22665 9 35 480 284 5 150 4 172 112 167 21631 336 385 39 4 172 4536 1111 17 546 38 13 447 4 192 50 16 6 147 2025 19 14 22 4 1920 4613 469 4 22 71 87 12 16 43 530 38 76 15 13 1247 4 22 17 515 17 12 16 626 18 19193 5 62 386 12 8 316 8 106 5 4 2223 5244 16 480 66 3785 33 4 130 12 16 38 619 5 25 124 51 36 135 48 25 1415 33 6 22 12 215 28 77 52 5 14 407 16 82 10311 8 4 107 117 5952 15 256 4 31050 7 3766 5 723 36 71 43 530 476 26 400 317 46 7 4 12118 1029 13 104 88 4 381 15 297 98 32 2071 56 26 141 6 194 7486 18 4 226 22 21 134 476 26 480 5 144 30 5535 18 51 36 28 224 92 25 104 4 226 65 16 38 1334 88 12 16 283 5 16 4472 113 103 32 15 16 5345 19 178 32\n",
            "[    0 15000 30241 20726 53932 62275 87848 21873 14715 70354 55709 55048\n",
            " 70824 46855 47086 23797 44161 34875 58030 33982  1390 81707  5914 60351\n",
            " 71449 83893 43328 57145 37891 18919 23687 22585 42455 46243 46460 55560\n",
            "  5781 22969 62941 45679 11611 55050 26644 65496 17397 28207 25992 26696\n",
            " 56036 56285 74684 82829  8008 76778 17972 10338 61327 69342 24482 68994\n",
            " 46293 78325 40869  3193 31031 61911 45636 41878 12775 68961 10114 60894\n",
            " 13892 56933 16249 29839 37262 77154 61483 52534 81070  2453  3457  7223\n",
            " 65381 72542 45544 75365 56797 35127 52248 40921 55786  9481  2295  2611\n",
            " 83209 46055 39113 87990 41082 28609 63607 16135 26825 76317 31295 28811\n",
            " 13678 16749 39269 63407 31134 86065 13595 37839 55078  6161  2317 62430\n",
            " 24286   108 15330 30360 21180 54156 48193 23825 44269 34900 58991 33985\n",
            "  1475 54215  5964 84577 43603 37915 58519 18961 48139 46254 46551 23325\n",
            " 45726 12384 55062 48381 26688 60373 21284 65863 28208 26030 30549 48386\n",
            " 56293 48764 30699 74830 82845  8185 45950 76805 18061 11752 10342 30385\n",
            " 23318 61334 23000 21350 59936 69124 46294  8918 79250 40896 78358  3272\n",
            " 59420 48910 21214 42039 47623 12781 21115 45921 68972 34023 10190 61032\n",
            " 44201 13947 56999 34053 16253 42108 66346 30276  8405 29853 37559 77257\n",
            " 61675 58432 15581 21418 79407 47216 18350 34894 60042 44412 74780 56806\n",
            " 35375 40942 55918 73370  2298 11633 83291 50115 46063 18426 88041 28610\n",
            " 35186 16160 66171 24724 48925 31323 30429 28955 35408 57158 58462 16792\n",
            " 24861 44305 37376 86131 33991  2684 31334 70384 83214 21040 37855 58574\n",
            "  6164  2365 41138 18174 26061 24317   116 15347 30369 58992 84594 58522\n",
            " 46255 46562 12388 60386 21290 26034 15383 56295 48866  8245 45955 76806\n",
            " 11755 48794 23319 61335 23006  8266 69125 46296  8926 78382 42042 47627\n",
            " 12782  8236 58993 34033 10198 13948 42114 66349  8406 29858 37593 79410\n",
            " 44425 40943 55947 16162 24759 48936 58464 24864 61036 86132 33995 48943\n",
            " 70385 83217 41140]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0D47t-NRPyj",
        "outputId": "628334aa-0cd6-4951-aa12-1bd373305f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"document-term matrix shape (training): (%s, %s)\" % (dtm_train.shape))\n",
        "print(\"document-term matrix shape (test): (%s, %s)\" % (dtm_train.shape))\n",
        "num_words = len([v for k,v in veczr.vocabulary_.items()]) + 1 # add 1 for 0 padding\n",
        "print('vocab size:%s' % (num_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document-term matrix shape (training): (25000, 88584)\n",
            "document-term matrix shape (test): (25000, 88584)\n",
            "vocab size:88585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R-ZS0UmRQAh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM0T9i9QHLkl"
      },
      "source": [
        "def dtm2wid(dtm, maxlen=2000):\n",
        "    x = []\n",
        "    nwds = []\n",
        "    for idx, row in enumerate(dtm):\n",
        "        seq = []\n",
        "        indices = (row.indices + 1).astype(np.int64)\n",
        "        np.append(nwds, len(indices))\n",
        "        data = (row.data).astype(np.int64)\n",
        "        count_dict = dict(zip(indices, data))\n",
        "        for k,v in count_dict.items():\n",
        "            seq.extend([k]*v)\n",
        "        num_words = len(seq)\n",
        "        nwds.append(num_words)\n",
        "        # pad up to maxlen\n",
        "        if num_words < maxlen: \n",
        "            seq = np.pad(seq, (maxlen - num_words, 0), mode='constant')\n",
        "        # truncate down to maxlen\n",
        "        else:                  \n",
        "            seq = seq[-maxlen:]\n",
        "        x.append(seq)\n",
        "    nwds = np.array(nwds)\n",
        "    print('sequence stats: avg:%s, max:%s, min:%s' % (nwds.mean(), nwds.max(), nwds.min()) )\n",
        "    return np.array(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyClhse0GeWq",
        "outputId": "eeb43449-6119-4d5e-d0f6-c29e017282a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "maxlen = 2000\n",
        "x_train = dtm2wid(dtm_train, maxlen=maxlen)\n",
        "x_test = dtm2wid(dtm_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequence stats: avg:309.9618, max:1670, min:16\n",
            "sequence stats: avg:300.58584, max:2079, min:6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRUuMsUhG2-G"
      },
      "source": [
        "#Probability of a word appearing in a document in one class , \n",
        "#p all items with label ( 0 or 1)\n",
        "def pr(dtm, y, y_i):\n",
        "    p = dtm[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)\n",
        "nbratios = np.log(pr(dtm_train, y_train, 1)/pr(dtm_train, y_train, 0))\n",
        "nbratios = np.squeeze(np.asarray(nbratios))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zle42zZRa2aQ",
        "outputId": "bffc759d-accc-4e51-8be7-f9775fa18970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( nbratios[0:10]) \n",
        "print( nbratios.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.          0.02469261  0.02469261  0.          0.35667494 -0.18232156\n",
            "  0.08004271  0.01904819 -1.09861229  0.26826399]\n",
            "(88584,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I93YMKesbOF5",
        "outputId": "0237c8a8-d244-435d-e9d5-d671b403c68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dtm_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x88584 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 315 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDYCoMnjeEyl",
        "outputId": "688b0ed8-2850-4814-ef7f-5bed48630347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def pr_index(dtm, y, y_i,index_key):\n",
        "    p = dtm[index_key][y[index_key]==y_i].sum(0)\n",
        "    print(index_key,\" ) \",p.shape )\n",
        "    return (p+1) / ((y[index_key]==y_i).sum()+1)\n",
        "\n",
        "pr_index(dtm_train, y_train, 1,838)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "838  )  (1, 88584)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2., 1., 1., ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q75vwl9kaQvP",
        "outputId": "d33d966b-ae68-4bd4-ecc4-77b86f2cb809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "index = 838\n",
        "dtm = dtm_train[index]\n",
        "y = y_train[index]\n",
        "y_i = 1\n",
        "\n",
        "p = dtm[y==y_i]\n",
        "p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x88584 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 263 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTk6MvFXXuV_",
        "outputId": "ee8d95a6-eb36-41e6-8f37-bc468f98a4ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p.sum(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnQKcGfKiOB-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqad121XUqNG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ5VeaAcXFRz",
        "outputId": "334b9867-406b-40e2-dc26-cf967a7ab8b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#indices contributing most to label 1\n",
        "np.argsort(nbratios)[:-30:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  838, 75629, 63102,  1327, 53766, 41455, 55053, 24686, 52431,\n",
              "       24244, 35408, 65865,  1299, 84021, 46430, 11714, 40076,  1292,\n",
              "         195,  1230,  2952, 45406, 71926, 10943,  8818, 84915, 84599,\n",
              "       20743, 42222])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBHM5SYPXXib",
        "outputId": "c76c0dbf-47ca-4ef0-91b0-bee4a59a4bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"most\")\n",
        "for id in np.argsort(nbratios)[:-20:-1]:\n",
        "  print(\"index\",id,\"  -> \",index_to_word[id], \" ratio \", nbratios[id])  \n",
        "  \n",
        "print(\"less\")\n",
        "for id in np.argsort(nbratios)[0:10]:\n",
        "  print(\"index\",id,\"  -> \",index_to_word[id], \" ratio \", nbratios[id])    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "most\n",
            "index 838   ->  atmosphere  ratio  3.970291913552122\n",
            "index 75629   ->  «boy  ratio  3.8918202981106265\n",
            "index 63102   ->  spacecrafts  ratio  3.8501476017100584\n",
            "index 1327   ->  climax  ratio  3.6888794541139363\n",
            "index 53766   ->  1871  ratio  3.6888794541139363\n",
            "index 41455   ->  recipients  ratio  3.637586159726386\n",
            "index 55053   ->  marshal  ratio  3.6109179126442243\n",
            "index 24686   ->  fred's  ratio  3.58351893845611\n",
            "index 52431   ->  dominque  ratio  3.5263605246161616\n",
            "index 24244   ->  starlift  ratio  3.4657359027997265\n",
            "index 35408   ->  jaundiced  ratio  3.4011973816621555\n",
            "index 65865   ->  truce  ratio  3.4011973816621555\n",
            "index 1299   ->  subtle  ratio  3.4011973816621555\n",
            "index 84021   ->  screwloose  ratio  3.367295829986474\n",
            "index 46430   ->  apostle  ratio  3.349904087274605\n",
            "index 11714   ->  trunk  ratio  3.349904087274605\n",
            "index 40076   ->  leaks  ratio  3.332204510175204\n",
            "index 1292   ->  silent  ratio  3.332204510175204\n",
            "index 195   ->  that's  ratio  3.295836866004329\n",
            "less\n",
            "index 15056   ->  senate  ratio  -4.290459441148391\n",
            "index 37150   ->  standers  ratio  -4.2626798770413155\n",
            "index 46846   ->  ruehl  ratio  -4.219507705176107\n",
            "index 11676   ->  shane  ratio  -4.189654742026426\n",
            "index 33911   ->  raveena  ratio  -4.127134385045092\n",
            "index 1168   ->  van  ratio  -4.110873864173311\n",
            "index 68112   ->  wire'fu  ratio  -4.0943445622221\n",
            "index 15473   ->  patrons  ratio  -4.07753744390572\n",
            "index 80759   ->  lutzky  ratio  -4.02535169073515\n",
            "index 49158   ->  abreast  ratio  -4.007333185232471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ZDpoDMG4en"
      },
      "source": [
        "def get_model(num_words, maxlen, nbratios=None):\n",
        "    embedding_matrix = np.zeros((num_words, 1))\n",
        "    for i in range(1, num_words): # skip 0, the padding value\n",
        "        if nbratios is not None:\n",
        "            # if log-count ratios are supplied, then it's NBSVM\n",
        "            embedding_matrix[i] = nbratios[i-1]\n",
        "        else:\n",
        "            # if log-count rations are not supplied, this reduces to a logistic regression\n",
        "            embedding_matrix[i] = 1\n",
        "\n",
        "    # set up the model\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    r = Embedding(num_words, 1, input_length=maxlen, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Embedding(num_words, 1, input_length=maxlen, embeddings_initializer='glorot_normal')(inp)\n",
        "    x = dot([r,x], axes=1)\n",
        "    x = Flatten()(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(lr=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcWYxQA6UVBx",
        "outputId": "653f0cc0-1d68-4735-820e-e2d1be5327e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = get_model(num_words, maxlen, nbratios=nbratios)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2691 - accuracy: 0.9434 - val_loss: 0.2504 - val_accuracy: 0.9214\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.0783 - accuracy: 0.9913 - val_loss: 0.2252 - val_accuracy: 0.9240\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.0392 - accuracy: 0.9981 - val_loss: 0.2141 - val_accuracy: 0.9249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b930ff748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWGpi2O_UXaU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}